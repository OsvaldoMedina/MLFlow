{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __MLflow - Red Neuronal__\n",
    "\n",
    "## __Generator v.0__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Objective__\n",
    "\n",
    "- Develop an exercise with MLflow to learn about this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paginas para revisar:\n",
    "\n",
    "- https://www.mlflow.org/\n",
    "- https://learn.microsoft.com/en-us/azure/databricks/_static/notebooks/mlflow/mlflow-model-registry-example.html\n",
    "- https://learn.microsoft.com/en-us/azure/databricks/mlflow/model-registry-example\n",
    "- https://medium.com/@haythemtellili/end-to-end-ml-pipelines-with-mlflow-projects-63a11baa2dd1\n",
    "- https://medium.com/@kevin.n.lu123/mlflow-managing-your-ml-pipeline-from-training-to-deployment-7e0d87df9d\n",
    "- https://crunchingthedata.com/cs01-mlflow-models/\n",
    "- https://medium.com/noodle-labs-the-future-of-ai/introduction-to-mlflow-for-mlops-part-1-anaconda-environment-1fd9e299226f\n",
    "- https://medium.com/noodle-labs-the-future-of-ai/introduction-to-mlflow-for-mlops-part-2-docker-environment-53516ce45266\n",
    "- https://medium.com/noodle-labs-the-future-of-ai/introduction-to-mlflow-for-mlops-part-3-database-tracking-minio-artifact-storage-and-registry-9fef196aaf42\n",
    "- https://kili-technology.com/blog/how-to-manage-your-machine-learning-pipeline-with-mlflow\n",
    "- https://analyticsindiamag.com/kubeflow-vs-mlflow-which-mlops-tool-should-you-use/\n",
    "\n",
    "MLflow - Storing Artifacts in HDFS and in an SQLite DB: \n",
    "\n",
    "- https://medium.com/@moyukh_51433/mlflow-storing-artifacts-in-hdfs-and-in-an-sqlite-db-7be26971b6ab\n",
    "\n",
    "Cursos udemy:\n",
    "- https://www.udemy.com/course/azure-machine-learning-mlops-mg/\n",
    "\n",
    "Youtube:\n",
    "\n",
    "- https://www.youtube.com/watch?v=wb-ZxtIwSTA\n",
    "- https://www.youtube.com/watch?v=JApPzAnbfPI\n",
    "- https://www.youtube.com/watch?v=SCwi3b29qwY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "# !pip install pyyaml\n",
    "#!pip install sqlparse\n",
    "#!pip install #!pip installquerystring-parser\n",
    "#!pip install flask\n",
    "#!pip install waitress\n",
    "#!pip install waitress threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.argv\n",
    "print(sys.argv, len(sys.argv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "# Create an experiment name, which must be unique and case sensitive\n",
    "experiment_id_tf = mlflow.create_experiment(\n",
    "    \"TF Experiments\",\n",
    "    artifact_location=Path.cwd().joinpath(\"tutorial_mlflow/mlflow-tensorflow\").as_uri(),\n",
    "    tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_tf = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment(experiment_id_tf)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "#print(\"Creation timestamp: {}\".format(experiment.creation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviar experimento a la carpeta de \"trash\"\n",
    "# Fuente: https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.delete_experiment\n",
    "import mlflow\n",
    "\n",
    "experiment_id = mlflow.create_experiment(\"Experiment_NEW\")\n",
    "#experiment_id = '0'\n",
    "mlflow.delete_experiment(experiment_id)\n",
    "\n",
    "# Examine the deleted experiment details.\n",
    "experiment = mlflow.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "#print(\"Last Updated timestamp: {}\".format(experiment.last_update_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se tiene que eliminar de la base datos\n",
    "\n",
    "* DELETE FROM experiments WHERE experiment_id = 1;\n",
    "* DELETE FROM experiment_tags WHERE experiment_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X,y = make_blobs(n_samples=1000, n_features=2, centers=2, random_state=42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:, 1], c=y, marker=\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "\n",
    "def train_keras_model(X, y,learning_rates,optimizer,epochs,batch_size,validation_split):\n",
    "  optimizer=keras.optimizers.Adam(learning_rate=learning_rates)\n",
    "\n",
    "  model_anr = Sequential()\n",
    "  model_anr.add(Dense(8, input_shape=(X_train.shape[-1],), activation=\"relu\", name=\"hidden_layer\"))\n",
    "  model_anr.add(Dense(1,activation = \"sigmoid\"))\n",
    "  model_anr.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"binary_accuracy\"])\n",
    "\n",
    "  history = model_anr.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "  fig, ax = plt.subplots(2,1)\n",
    "  ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "  ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "  legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "  ax[1].plot(history.history['binary_accuracy'], color='b', label=\"Training binary accuracy\")\n",
    "  ax[1].plot(history.history['val_binary_accuracy'], color='r',label=\"Validation binary accuracy\")\n",
    "  legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "  test_loss, test_binary_accuracy = model_anr.evaluate(X_test, y_test)\n",
    "  print(\"Test test_binary_accuracy: {}\".format(test_binary_accuracy))\n",
    "\n",
    "  mlflow.log_metric(\"test_loss\", test_loss)\n",
    "  mlflow.log_metric(\"test_binary_accuracy\", test_binary_accuracy)\n",
    "  return model_anr, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_tf = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiment = \"Experiment 5\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    mlflow.keras.autolog()\n",
    "    #mlflow.autolog()\n",
    "    #with mlflow.start_run(experiment_id=experiment_id_tf) as run:\n",
    "    with mlflow.start_run(experiment_id=experiment_id_tf, run_name=num_experiment) as run:\n",
    "\n",
    "          # Automatically capture the model's parameters, metrics, artifacts,\n",
    "            # and source code with the `autolog()` function\n",
    "            #mlflow.keras.autolog()\n",
    "\n",
    "            mlflow.set_tag(\"mlflow.runName\", num_experiment)\n",
    "\n",
    "            learning_rates = 0.001\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rates)\n",
    "            epochs = 10\n",
    "            batch_size = 32\n",
    "            validation_split = 0.1\n",
    "\n",
    "            model_anr, history  = train_keras_model(X, y,learning_rates,optimizer,epochs,batch_size,validation_split)\n",
    "\n",
    "            # get model signature\n",
    "            signature = infer_signature(model_input=X_train, model_output=model_anr.predict(X_train))\n",
    "\n",
    "            # Save the plot and log it as an artifact\n",
    "            \n",
    "            plt.savefig(\"behavior_plot.png\")\n",
    "            mlflow.log_artifact(\"behavior_plot.png\")\n",
    "\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "            print('tracking_url_type_store:',tracking_url_type_store)\n",
    "\n",
    "            #from tensorflow.python.saved_model import signature_constants\n",
    "            #tag=[keras.saved_model.tag_constants.SERVING]\n",
    "            #tag=[tensorflow.compat.v1.saved_model.tag_constants.SERVING]\n",
    "            #key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                # Save model to artifacts\n",
    "                mlflow.keras.log_model(keras_model = model_anr, artifact_path='keras-models',signature=signature,\n",
    "                registered_model_name=\"keras-modelo-1\")\n",
    "            else:\n",
    "                # Save model to artifacts\n",
    "                mlflow.keras.log_model(keras_model = model_anr, artifact_path=\"keras-models\",signature=signature,\n",
    "                registered_model_name=\"keras-modelo-1\")\n",
    "                #mlflow.keras.log_model()\n",
    "\n",
    "# fetch the auto logged parameters and metrics for ended run\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "\n",
    "mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('gpw_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "983647796b41a55e68a33a57e424b28a5a72da4c8a19017d375c381b1abbbc53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
